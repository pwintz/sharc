#!/usr/bin/env python3
""" 
This script computes the evolution of a system (plant) using control imputs received from a controller executable. 
The communication is done via pipe files contained in the simdir directory.
Instead of calling this script directly, call run_scarabintheloop.py
"""
import numpy as np
from scipy.integrate import ode
import scipy.signal
import numpy.linalg as linalg
import copy
# import argparse # Parsing of input args.

# Import contextmanager to allow defining commands to be used to create "with" blocks.
from contextlib import contextmanager 

import math
import time
import datetime
import traceback # Provides pretty printing of exceptions (https://stackoverflow.com/a/1483494/6651650)
from abc import abstractmethod, ABC

import scarabintheloop.scarabizor as scarabizor
from scarabintheloop.scarabizor import ScarabPARAMSReader
from scarabintheloop.utils import *

import json
import csv
import re
import os

from typing import List, Set, Dict, Tuple, Union


class DataNotRecievedViaFileError(IOError):
  pass

debug_interfile_communication_level = 0
debug_dynamics_level = 0

class PipeReader:
  def __init__(self, filename: str):
    if debug_interfile_communication_level >= 1:
      print(f"About to open reader for {filename}. Waiting for it to available...")
    self.file = open(filename, 'r', buffering=1)

  def close(self):
    self.file.close()

  def read(self):
    input_line = self._waitForLineFromFile()
    input_line = checkAndStripInputLoopNumber(input_line)
    return input_line

  def _waitForLineFromFile(self):
    if debug_interfile_communication_level >= 1:
          print(f"Waiting for input_line from {self.file.name}.")
    input_line = self.file.readline()
    if debug_interfile_communication_level >= 1:
      print(f'Recieved input_line from {os.path.basename(self.file.name)}: {repr(input_line)}')
    return input_line

class PipeFloatReader(PipeReader):
  
  def __init__(self, filename: str):
    super().__init__(filename)

  def read(self):
    return float(super().read())

class PipeVectorReader(PipeReader):

  def __init__(self, filename: str):
    super().__init__(filename)

  def read(self):
    return convertStringToVector(super().read())

class DelayProvider(ABC):

  @abstractmethod
  def get_delay(self, metadata):
    """ 
    return t_delay, metadata 
    """
    # raise NotImplementedError(f'get_delay must be implemented by a subclass of DelayProvider.')
    return t_delay, instruction_count, cycles_count

class ScarabDelayProvider(DelayProvider):

  def __init__(self, sim_dir):
    self._stats_file_number = 0
    self.stats_reader = scarabizor.ScarabStatsReader(sim_dir)
    self.scarab_params_reader = ScarabPARAMSReader(sim_dir)

  def get_delay(self, metadata):
    if debug_interfile_communication_level >= 2:
      print('Waiting for statistics from Scarab.')

    self.stats_reader.waitForStatsFile(self._stats_file_number)
    t_delay = self.stats_reader.readTime(self._stats_file_number)
    instruction_count = self.stats_reader.readInstructionCount(self._stats_file_number)
    cycles_count = self.stats_reader.readCyclesCount(self._stats_file_number)
    self._stats_file_number += 1

    delay_metadata = {}
    params_out = self.scarab_params_reader.params_out_to_dictionary()
    delay_metadata.update(params_out)
    delay_metadata["instruction_count"] = instruction_count
    delay_metadata["cycles_count"] = cycles_count
    return t_delay, delay_metadata

class OneTimeStepDelayProvider(DelayProvider):

  def __init__(self, sample_time):
    self.sample_time = sample_time
    
  def get_delay(self, metadata):
    t_delay = self.sample_time
    metadata = {}
    return t_delay, metadata

class NoneDelayProvider(DelayProvider):

  def __init__(self):
    pass

  def get_delay(self, metadata):
    t_delay = None
    metadata = {}
    return t_delay, metadata

class GaussianDelayProvider(DelayProvider):

  def __init__(self, mean, std_dev):
    self.mean = mean
    self.std_dev = std_dev

  def get_delay(self, metadata):
    # Generate a random number from the Gaussian distribution
    t_delay = np.random.normal(self.mean, self.std_dev)
    metadata = {}
    return t_delay, metadata

class LinearBasedOnIteraionsDelayProvider(DelayProvider):
  
  def __init__(self):
    pass

  def get_delay(self, metadata):
    # TODO: Move the computation delays generated by a model out of the plant_runner module.
    iterations = metadata["iterations"]
    delay_model_slope       = config_data["computation_delay_model"]["computation_delay_slope"]
    delay_model_y_intercept = config_data["computation_delay_model"]["computation_delay_y-intercept"]
    if delay_model_slope:
      if not delay_model_y_intercept:
        raise ValueError(f"delay_model_slope was set but delay_model_y_intercept was not.")
      t_delay = delay_model_slope * iterations + delay_model_y_intercept
      print(f"t_delay = {t_delay:.8g} = {delay_model_slope:.8g} * {iterations:.8g} + {delay_model_y_intercept:.8g}")
    else:
      print('Using constant delay times.')
      t_delay = config_data["computation_delay_model"]["fake_computation_delay_times"]
    return t_delay, metadata


class ControllerInterface(ABC):
  """ 
  Create an Abstract Base Class (ABC) for a controller interface. 
  This handles communication to and from the controller, whether that is an executable or (for testing) a mock controller.
  """

  def __init__(self, computational_delay_provider: DelayProvider):
    self.computational_delay_provider = computational_delay_provider

  def open(self):
    """
    Open any resources that need to be closed.
    """
    pass

  def close(self):
    """
    Do cleanup of opened resources.
    """
    pass

  @abstractmethod
  def _write_x(self, x: np.ndarray):
    pass

  @abstractmethod
  def _write_t_delay(self, t: float):
    pass
    
  @abstractmethod
  def _read_u(self) -> np.ndarray:
    return u
    
  # TODO: Instead of having separate data streams for things like x_prediction and iterations, which 
  # TODO: will depend on the given system, write all of the system-specific data to a JSON file.
  # def _read_metadata(self, k) -> dict:
  #   pass

  @abstractmethod
  def _read_x_prediction(self) -> np.ndarray:
    return x_prediction
    
  @abstractmethod
  def _read_t_prediction(self) -> float:
    return t_prediction

  @abstractmethod
  def _read_iterations(self) -> int:
    return iterations
    
  def _read_metadata(self) -> int:
    x_prediction = self._read_x_prediction()
    t_prediction = self._read_t_prediction()
    iterations = self._read_iterations()
    if isinstance(x_prediction, np.ndarray):
      x_prediction = numpy_vec_to_list(x_prediction)
    metadata = {
      "x_prediction": x_prediction,
      "t_prediction": t_prediction,
      "iterations": iterations
    }

    return metadata
    
  def get_next_control_from_controller(self, x: np.ndarray):
    """
    Send the current state to the controller and wait for the responses. 
    Return values: u, x_prediction, t_prediction, iterations.
    """

    # The order of writing and reading to the pipe files must match the order in the controller.
    self._write_x(x)
    u = self._read_u()
    metadata = self._read_metadata() # TODO
    u_delay, delay_metadata = self.computational_delay_provider.get_delay(metadata)
    self._write_t_delay(u_delay)
    metadata.update(delay_metadata)

    if debug_interfile_communication_level >= 1:
      print('Input strings from C++:')
      printIndented(f"           u: {u}", 1)
      printIndented(f"metadata: {metadata}", 1)

    return u, u_delay, metadata
    
class PipesControllerInterface(ControllerInterface):

  def __init__(self, computational_delay_provider: DelayProvider, sim_dir):
    self.computational_delay_provider = computational_delay_provider
    self.sim_dir = sim_dir

  def open(self):
    """
    Open resources that need to be closed when finished.
    """
    self.x_infile = PipeVectorReader(self.sim_dir + '/x_c++_to_py') 
    self.u_infile = PipeVectorReader(self.sim_dir + '/u_c++_to_py') 
    self.x_predict_infile = PipeVectorReader(self.sim_dir + '/x_predict_c++_to_py') 
    self.t_predict_infile = PipeFloatReader(self.sim_dir + '/t_predict_c++_to_py') 
    self.iterations_infile = PipeFloatReader(self.sim_dir + '/iterations_c++_to_py') 
    self.x_outfile = file = open(self.sim_dir + 'x_py_to_c++', 'w', buffering=1)
    self.t_delay_outfile = file = open(self.sim_dir + 't_delay_py_to_c++', 'w', buffering=1)
    
    if debug_interfile_communication_level >= 1:
      print('Pipes are open') 

    return self  # Return the instance so that it's accessible as 'as' target

  def close(self):
    """ 
    Close all of the files we opened.
    """
    # Code to release the resource (e.g., close a file, database connection)
    self.x_infile.close()
    self.u_infile.close()
    self.x_predict_infile.close()
    self.t_predict_infile.close()
    self.iterations_infile.close()
    self.x_outfile.close()
    self.t_delay_outfile.close()

  def _write_x(self, x: np.ndarray):
    write_vec_to_file(self.x_outfile, x)

  def _write_t_delay(self, t_delay: float):
    t_delay_str = f"{t_delay:.8g}"
    self.t_delay_outfile.write(str(t_delay_str) + "\n")

  def _read_u(self):
    return self.u_infile.read()
    
  def _read_x_prediction(self):
    return self.x_predict_infile.read()
    
  def _read_t_prediction(self):
    return self.t_predict_infile.read()
    
  def _read_iterations(self):
    return self.iterations_infile.read()
      

def write_vec_to_file(file, x: np.ndarray):
  # Pass the string back to C++.
  x_out_string = nump_vec_to_csv_string(x)
  if debug_interfile_communication_level >= 1:
    print("x output line:" + repr(x_out_string))
  file.write(x_out_string + "\n")# Write to pipe to C++



class ComputationData:

  def __init__(self, t_start, delay, u, metadata={}):
    self.t_start = t_start
    self.delay = delay
    self.t_end = t_start + delay
    self.u = u
    self.metadata = metadata

  def __bool__(self):
    return True

  def __str__(self):
    if self.metadata:
      # return f'ComputationData(t_start={self.t_start}, delay={self.delay}, t_end={self.t_end}, u<{type(self.u)}>={self.u}, metadata={self.metadata})'
      return f'ComputationData(t_start={self.t_start}, delay={self.delay})'
    else:
      # return f'ComputationData(t_start={self.t_start}, delay={self.delay}, t_end={self.t_end}, u<{type(self.u)}>={self.u})'
      return f'ComputationData(t_start={self.t_start}, delay={self.delay})'


  def __repr__(self):
    if self.metadata:
      # return f'ComputationData(t_start={self.t_start}, delay={self.delay}, t_end={self.t_end}, u<{type(self.u)}>={self.u}, metadata={self.metadata})'
      return f'ComputationData(t_start={self.t_start}, delay={self.delay})'
    else:
      # return f'ComputationData(t_start={self.t_start}, delay={self.delay}, t_end={self.t_end}, u<{type(self.u)}>={self.u})'
      return f'ComputationData(t_start={self.t_start}, delay={self.delay})'

  
  # def toJSON(self):
  #     return json.dumps(
  #         self,
  #         default=lambda o: o.__dict__, 
  #         sort_keys=True,
  #         indent=4)

  # def __dict__(self):
  #   return {"t_start": self.t_start,
  #           "delay": self.delay,
  #           "t_end": self.t_end,
  #           "u": self.u,
  #           "metadata": self.metadata
  #         }      

  def copy(self):
    return ComputationData(self.t_start, self.delay, copy.deepcopy(self.u), copy.deepcopy(self.metadata))

  def __eq__(self, other):
    """ Check the equality of the *data* EXCLUDING metadata. """
    return self.t_start == other.t_start \
       and self.delay == other.delay     \
       and self.t_end == other.t_end     \
       and self.u == other.u #            \
      #  and self.metadata == other.metadata 

  def next_batch_initialization_summary(self) -> str:
    if isinstance(self.u, np.ndarray):
      return f't_end={self.t_end}, u[0]={self.u[0][0]}'
    else:
      return f't_end={self.t_end}, u[0]={self.u[0]}'


class TimeStepSeries:

  def __init__(self, k0, t0, x0, pending_computation_prior=None):
    if k0 is None:
      raise ValueError("k0 is None")
    if t0 is None:
      raise ValueError("t0 is None")
    if x0 is None:
      raise ValueError("x0 is None")
    
    # Initial values
    self.k0 = k0
    self.t0 = t0
    self.x0 = self.cast_vector(x0)

    # Unlike k0, t0, and x0, "pending_computation_prior" is not stored in the data arrays. 
    # Instead, it simple is used to record what the 'incoming' computation was, if any.
    self.pending_computation_prior = pending_computation_prior
    
    ### Time-index aligned values ###
    self.x = []
    self.u = []
    self.t = []
    self.k = [] # Time step number
    self.i = [] # Sample index number

    # Note: self.pending_computation[j] is the computation that was either started at self.t[j] 
    #       or previously started and is still continuing at self.t[j].
    self.pending_computation = []
    
    # Some Metadata for the simulation
    self._walltime_start: float = time.time()
    self.walltime = None
    self.cause_of_termination: str = "In Progress"
    self.datetime_of_run = datetime.datetime.now().isoformat()


  def finish(self, cause_of_termination=None):
    self.walltime = time.time() - self.walltime_start
    if not cause_of_termination:
      self.cause_of_termination = "Finished"
    else:
      self.cause_of_termination = repr(cause_of_termination)

  def get_pending_computation_for_time_step(self, k):
    ndx = self.k.index(k)
    return self.pending_computation[ndx]

  def get_pending_computation_started_at_sample_time_index(self, i):
    ndx = self.i.index(i)
    if ndx > 0:
      # If not the very first entry, then we need to increment the ndx by one because the value of 'i' increments (in the array) on entry before pending_computation "increments" (gets a new value).
      ndx += 1
    print(f'ndx from i={i}: {ndx}. (self.i: {self.i})')
    # if self.pending_computation[ndx] is None:
      # return self.pending_computation[ndx + 1]
    if self.i[ndx] != i:
      raise ValueError("self.i[ndx] != i")
    
    return self.pending_computation[ndx]


  def __repr__(self):
      return (f"{self.__class__.__name__}("
              f"k0={self.k0},\n "
              f"t0={self.t0},\n "
              f"x0={self.x0},\n "
              f"pending_computation_prior={self.pending_computation_prior},\n"
              f" x={self.x},\n "
              f" u={self.u},\n "
              f" t={self.t},\n "
              f" k={self.k},\n "
              f" i={self.i},\n "
              f"pending_computation={self.pending_computation})")

  def cast_vector(self, x):
    if x is None:
      return None
    if isinstance(x, float) or isinstance(x, int) or isinstance(x, list):
      return x
    elif isinstance(x, np.ndarray):
      return numpy_vec_to_list(x)
    raise ValueError(f'cast_vector(): Unexpected type: {type(x)}')
    

  def copy(self):
    copied = TimeStepSeries(self.k0, self.t0, self.x0, self.pending_computation_prior)

    # Copy values.
    copied.x                   = self.x.copy()
    copied.u                   = self.u.copy()
    copied.t                   = self.t.copy()
    copied.k                   = self.k.copy()
    copied.i                   = self.i.copy()
    copied.pending_computation = self.pending_computation.copy()
    return copied

  def append(self, t_end, x_end, u, pending_computation: ComputationData, t_mid=None, x_mid=None, ):

    # is_x_end_None = x_end is None
    x_end     = self.cast_vector(x_end)
    u         = self.cast_vector(u)
    x_mid     = self.cast_vector(x_mid)

    if x_end is None:
      raise ValueError(f'x_end is None')

    if pending_computation.t_end > t_end:
      raise ValueError("pending_computation.t_end > t_end")
    

    if len(self.t) == 0:
      k       = self.k0
      t_start = self.t0
      x_start = self.x0
    else:
      k = self.k[-1] + 1
      t_start = self.t[-1]
      x_start = self.x[-1]

    if t_mid is None != x_mid is None:
      raise ValueError("t_mid is None != x_mid is None")
    if t_start >= t_end:
      raise ValueError(f't_start={t_start} >= t_end={t_end}. self:{self}')
    if t_mid and (t_start > t_mid or t_mid > t_end):
      raise ValueError(f't_mid and (t_start > t_mid or t_mid > t_end)')

    if t_mid is None:
      #         [ Before, After] interval
      self.k += [      k,     k] # Step number
      self.i += [      k, k + 1] # Sample index
      self.t += [t_start, t_end]
      self.x += [x_start, x_end]
      self.u += [      u,     u]
      self.pending_computation += [pending_computation, pending_computation]

    else: # A mid point was given, indicating an update to u part of the way through.
      u_mid = pending_computation.u
      self.t += [t_start, t_mid, t_mid, t_end]
      self.x += [x_start, x_mid, x_mid, x_end]
      self.u += [       u,    u, u_mid, u_mid]
      self.k += [       k,    k,     k,     k]
      self.i += [       k,    k,     k, k + 1] # Sample index
      # The value of u_pending was applied, starting at t_mid, so it is no longer pending 
      # at the end of the sample. Thus, we set it to None.
      self.pending_computation += [pending_computation, pending_computation, None, None]

  def append_multiple(self, 
                      t_end: List, 
                      x_end: List, 
                      u: List, 
                      pending_computation: List, 
                      t_mid=None, 
                      x_mid=None):
    if len(t_end) != len(x_end):
      raise ValueError("len(t_end) != len(x_end)")

    if len(t_end) != len(u):
      raise ValueError("len(t_end) != len(u)")
    
    if len(t_end) != len(pending_computation):
      raise ValueError("len(t_end) != len(pending_computation)")

    for i in range(len(t_end)):
      if t_mid is None:
        i_t_mid = None
      else:
        i_t_mid = t_mid[i]

      if x_mid is None:
        i_x_mid = None
      else:
        i_x_mid = x_mid[i]

      self.append(t_end[i], x_end[i], u[i], pending_computation=pending_computation[i], t_mid=i_t_mid, x_mid=i_x_mid)

  def overwrite_computation_times(self, computation_times):
    if len(computation_times) != self.n_time_indices():
      raise ValueError(f"len(computation_times) = {len(computation_times)} != self.n_time_indices = {self.n_time_indices()}. self: {self}")
      
    print(f'Overwriting computation times. computation_times={computation_times}, self.pending_computation={self.pending_computation}.')
    i_pending_computation = 0
    i_computation_time = 0
    while i_pending_computation < len(self.pending_computation):
      pc = self.pending_computation[i_pending_computation]
      print()
      print(f'pc: ', pc)
      delay = computation_times[i_computation_time]
      print(f'computation_times[{i_computation_time}]', delay)
      new_pending_computation = ComputationData(t_start=pc.t_start, delay=delay, u=pc.u, metadata=pc.metadata)
      
      self.pending_computation[i_pending_computation] = new_pending_computation
      self.pending_computation[i_pending_computation+1] = new_pending_computation
      i_pending_computation += 2
      i_computation_time += 1

  # Override the + operator
  def __add__(self, other):
    if not isinstance(other, TimeStepSeries):
      raise ValueError(f'Cannot concatenate this TimeStepSeries with a {type(other)} object.')
    
    # if self.is_empty():
    #   raise ValueError('Cannot concatenate onto an empty TimeStepSeries')
    if other.is_empty():
      return self

    if not self.is_empty():
      if self.k[-1] + 1 != other.k0:
        raise ValueError(f"Initial k does not match: self.k[-1] + 1 = {self.k[-1] + 1} != other.k0 = {other.k0}")
      if self.t[-1] != other.t0:
        raise ValueError("Initial time does not match: self.t[-1] != other.t0")
      if self.x[-1] != other.x0:
        raise ValueError("Initial state does not match: self.x[-1] != other.x0")

    concatenated = self.copy()
    concatenated.x                   += other.x
    concatenated.u                   += other.u
    concatenated.t                   += other.t
    concatenated.k                   += other.k # Time step index
    concatenated.i                   += other.i # Sample time index
    concatenated.pending_computation += other.pending_computation

    return concatenated

  def truncate(self, last_k):
    """
    Truncate this object to either have n_timesteps or to end at the index last_k.
    """

    # if n_timesteps is None and last_k is None:
    #   raise ValueError("n_timesteps is None and last_k is None. Exactly one must be given!")
    
    # if n_timesteps is None:
    n_timesteps = last_k - self.k0
    n_timeindices = last_k - self.k0 + 1
    # elif last_k is None:
    #   last_k = self.k0 + n_timesteps
    # else:
    #   raise ValueError("Either n_timesteps or last_k must be None.")

    if last_k < self.k[0]:
      raise ValueError("last_k was less than the first time step.")

    if self.n_time_steps() <= n_timesteps:
      return self.copy()
    
    truncated = self.copy()

    # Time-index aligned values
    last_index_of_last_k = max(ndx for ndx, k in enumerate(self.k) if k == last_k)
    ndxs = slice(0, last_index_of_last_k+1)
    truncated.x                    = self.x[ndxs]
    truncated.u                    = self.u[ndxs]
    truncated.t                    = self.t[ndxs]
    truncated.k                    = self.k[ndxs]
    truncated.pending_computation  = self.pending_computation[ndxs]

    return truncated 

  def is_empty(self):
    return len(self.t) == 0

  def n_time_indices(self):
    if self.is_empty():
      return 0
    return self.i[-1] - self.i[0]

  def n_time_steps(self):
    if self.is_empty():
      return 0
    return self.k[-1] - self.k[0]

  def find_first_late_timestep(self, sample_time):
    for (i_step, pc) in enumerate(self.pending_computation):
      if pc.delay is not None and pc.delay > sample_time:
        has_missed_computation_time = True
        first_late_timestep = self.step_k[i_step]
        print(f'first_late_timestep: {first_late_timestep}')
        return first_late_timestep, has_missed_computation_time 
    
    has_missed_computation_time = False
    return None, has_missed_computation_time

  def printTimingData(self, label):
    timing_data = {
      "t0": self.t0,
      "k0": self.k0,
      "t": self.t,
      "k": self.k,
      "i": self.i
    }
    printJson(label, timing_data)
    
    print(f'{label}')
    TimeStepSeries.print_sample_time_values("k_time_step", self.k)
    TimeStepSeries.print_sample_time_values("i_sample_ndx", self.k)
    # TimeStepSeries.print_time_step_values("time step", self.step_k)
    TimeStepSeries.print_sample_time_values("t(k)", self.t)
    # TimeStepSeries.print_time_step_values("delay", self.pending_computation)

  def print(self, label):
    print(f'{label}: )')
    if self.pending_computation_prior:
      print("pending_computation_prior", self.pending_computation_prior.next_batch_initialization_summary())
    else:
      print("No prior pending computation.")
    TimeStepSeries.print_sample_time_values("k", self.k)
    # TimeStepSeries.print_time_step_values("time step", self.step_k)
    TimeStepSeries.print_sample_time_values("t(k)", self.t)
    TimeStepSeries.print_sample_time_values("x1(k)", [x[0] for x in self.x])
    # TimeStepSeries.print_sample_time_values("x2(k)", [x[1] for x in self.x])
    # TimeStepSeries.print_sample_time_values("x3(k)", [x[2] for x in self.x])
    TimeStepSeries.print_sample_time_values("x4(k)", [x[3] for x in self.x])
    TimeStepSeries.print_sample_time_values("u([k, k+1))", [u[0] for u in self.u])
    TimeStepSeries.print_sample_time_values("comp delay", [pc.delay for pc in self.pending_computation])
    TimeStepSeries.print_sample_time_values("comp u", [pc.u[0][0] for pc in self.pending_computation])
    TimeStepSeries.print_sample_time_values("comp t_end", [pc.t_end for pc in self.pending_computation])

  @staticmethod
  def print_sample_time_values(label: str, values: list):
    values = [float('nan') if v is None else v for v in values]
    print(f"{label:>18}: " +  " --- ".join(f"{v:^7.3g}" for v in values))

  @staticmethod
  def print_time_step_values(label: str, values: list):
    try:
      str_list = []
      for v in values:
        if v is None:
          str_list += ["  None "] 
        elif isinstance(v, (float, int)) :
          str_list += [f"{v:^7.3g}"]
        else:
          raise TypeError(f'Unxpected type: {type(v)}')
          
      print(f"{label:>18}:    |  " + "  |           |  ".join(str_list) + "  |")
    except Exception as err:
      print(f'Failed to print values in {values}. Error: {err}')
      raise err


#     # Read optimizer info.
#     # # TODO: Move the processing of the optimizer info out of "run_plant.py"
#     # with open(sim_dir + 'optimizer_info.csv', newline='') as csvfile:
#     #   csv_reader = csv.reader(csvfile, delimiter=',', quotechar='|')
#     #   
#     #   num_iterationss_list = []
#     #   costs_list = []
#     #   primal_residuals_list = []
#     #   dual_residuals_list = []
#     #   is_header = True
#     #   for row in csv_reader:
#     #     if is_header:
#     #       num_iterations_ndx = row.index('num_iterations')
#     #       cost_ndx = row.index('cost')
#     #       primal_residual_ndx = row.index('primal_residual')
#     #       dual_residual_ndx = row.index('dual_residual')
#     #       is_header = False
#     #     else:
#     #       num_iterationss_list.append(int(row[num_iterations_ndx]))
#     #       costs_list.append(float(row[cost_ndx]))
#     #       primal_residuals_list.append(float(row[primal_residual_ndx]))
#     #       dual_residuals_list.append(float(row[dual_residual_ndx]))
#     #     
#     # simulation_dictionary["num_iterations"]  = num_iterationss_list
#     # simulation_dictionary["cost"]            = costs_list
#     # simulation_dictionary["primal_residual"] = primal_residuals_list
#     # simulation_dictionary["dual_residual"]   = dual_residuals_list

def get_u(t, x, u_before, pending_computation_before: ComputationData, controller_interface):
  """ 
  Get an (possibly) updated value of u. 
  Returns: u, u_delay, u_pending, u_pending_time, metadata,
  where u is the value of u that should start being applied immediately (at t). 
  
  If the updated value requires calling the controller, then u_delay  

  This function is tested in <root>/tests/test_scarabintheloop_plant_runner.py/Test_get_u
  """
  
  print('pending_computation_before is None?', pending_computation_before is None)
  if pending_computation_before:
    print("NOT pending_computation_before. pending_computation_before: ", pending_computation_before)
  else:
    print("IS pending_computation_before. pending_computation_before: ", pending_computation_before)

  printHeader2('----- get_u (BEFORE) ----- ')
  print(f'u_before[0]: {u_before[0][0]}')
  print("pending_computation_before", pending_computation_before)
  printJson("pending_computation_before", pending_computation_before)

  did_start_computation = False
  if pending_computation_before is not None and pending_computation_before.t_end > t:
    # If last_computation is provided and the end of the computation is after the current time then we do not update anything. 
    # print(f'Keeping the same pending_computation: {pending_computation_before}')
    print(f'Set u_after = u_before = {u_before}. (Computation pending)')
    u_after = u_before
    pending_computation_after = pending_computation_before
    did_start_computation = False
    
    printHeader2('----- get_u (AFTER - no update) ----- ')
    print(f'u_after[0]: {u_after[0][0]}')
    printJson("pending_computation_after", pending_computation_after)
    print("pending_computation_after", pending_computation_after)
    return u_after, pending_computation_after, did_start_computation

  if pending_computation_before is not None and pending_computation_before.t_end <= t:
    # If the last computation data is "done", then we set u_after to the pending value of u.
    print(f'Set u_after = pending_computation_before.u = {pending_computation_before.u}. (computation finished)')
    u_after = pending_computation_before.u
  elif pending_computation_before is None:
    print(f'Set u_after = u_before = {u_before} (no pending computation).')
    u_after = u_before
  else:
    raise ValueError(f'Unexpected case.')
    

  # If there is not pen         ding_computation_before or the given pending_computation_before finishes before the current time t, then we run the computation of the next control value.
  u_pending, u_delay, metadata = controller_interface.get_next_control_from_controller(x)
  did_start_computation = True
  pending_computation_after = ComputationData(t, u_delay, u_pending, metadata)


  printHeader2('----- get_u (AFTER - With update) ----- ')
  print(f'u_after[0]: {u_after[0][0]}')
  printJson("pending_computation_after", pending_computation_after)
  # if u_delay == 0:
  #   # If there is no delay, then we update immediately.
  #   return u_pending, None
  if u_delay > 0:
    # print(f'Updated pending_computation: {pending_computation_after}')
    return u_after, pending_computation_after, did_start_computation
  else:
    raise ValueError(f'Expected a positive value.')
  

def computation_delay_provider_factory(computation_delay_name: str, sim_dir, sample_time):
  if isinstance(computation_delay_name, str):
    computation_delay_name = computation_delay_name.lower()
  if computation_delay_name == "none":
    return NoneDelayProvider()
  elif computation_delay_name == "gaussian":
    computational_delay_provider = GaussianDelayProvider(mean=0.24, std_dev=0.05)
  elif computation_delay_name == "execution-driven scarab":
    return ScarabDelayProvider(sim_dir)
  elif computation_delay_name == "onestep":
    return OneTimeStepDelayProvider(sample_time)
  elif isinstance(computation_delay_name, DelayProvider):
    return computation_delay_name
  else:
    raise ValueError(f'Unexpected computation_delay_name: {computation_delay_name}.')
    
@contextmanager
def controller_interface_factory(controller_interface_selection, computation_delay_provider, sim_dir):
  """ 
  Generate the desired ControllerInterface object based on the value of "controller_interface_selection". Typically the value will be the string "pipes", but a ControllerInterface interface object can also be passed in directly to allow for testing.
  
  Example usage:

    with controller_interface_factory("pipes", computation_delay_provider, sim_dir) as controller_interface: 
        <do stuff with controller_interface>
    
  When the "with" block is left, controller_interface.close() is called to clean up resources.
  """

  if isinstance(controller_interface_selection, str):
    controller_interface_selection = controller_interface_selection.lower()

  if controller_interface_selection == "pipes":
    controller_interface = PipesControllerInterface(computation_delay_provider, sim_dir)
  elif isinstance(controller_interface_selection, ControllerInterface):
    controller_interface = controller_interface_selection
  else:
    raise ValueError(f'Unexpected controller_interface: {controller_interface}')

  try:
    controller_interface.open()
    yield controller_interface.open()
  finally:
    controller_interface.close()

def run(sim_dir: str, config_data: dict, evolveState) -> dict:
  if not sim_dir.endswith("/"):
    sim_dir += "/"
  print(f"Start of plant_runner.run()  in {sim_dir}")

  # use_fake_scarab_computation_times = config_data["Simulation Options"]["use_fake_scarab_computation_times"]
  max_time_steps = config_data["max_time_steps"]
  sample_time = config_data["system_parameters"]["sample_time"] # Discrete sample period.
  first_time_index = config_data['first_time_index']

  computation_delay_provider = computation_delay_provider_factory(config_data["Simulation Options"]["in-the-loop_delay_provider"], sim_dir, sample_time)

  # Read the initial control value.
  x0 = list_to_numpy_vec(config_data['x0'])
  u0 = list_to_numpy_vec(config_data['u0'])
  
  # pending_computation may be None.
  pending_computation0 = config_data["pending_computation"]
  print(f"                  u0: {u0}")
  printJson(f"pending_computation0", pending_computation0)
  print(f"pending_computation0", pending_computation0)

  with controller_interface_factory("pipes", computation_delay_provider, sim_dir) as controller_interface:

    # computational_delay_provider = ScarabDelayProvider(sim_dir)
    # computational_delay_provider = OneTimeStepDelayProvider(sample_time)
    # computational_delay_provider = GaussianDelayProvider(mean=0.24, std_dev=0.05)

    try:
      x = x0
      u_before = u0
      u_before_str = repr(u_before)
      pending_computation_before = pending_computation0
      time_index = first_time_index

      # The number of time steps that the controller has been computed. 
      # When there is a pending 'u_before' value, there may be several time steps that don't compute new control values.
      n_new_u_values_computed = 0

      time_step_series = TimeStepSeries(k0=first_time_index, t0=time_index * sample_time, x0=x0, pending_computation_prior=pending_computation0)
      while n_new_u_values_computed < max_time_steps:
        t_start = time_index * sample_time
        t_mid = None
        t_end = (time_index + 1) * sample_time
        x_start = x
        x_mid = None

        u_after, pending_computation_after, did_start_computation = get_u(t_start, x_start, u_before, pending_computation_before, controller_interface)
        
        if pending_computation_before is None and (u_before != u_after):
          raise ValueError(f'There was no pending computation, but u changed from u_before={u_before} to u_after={u_after}.')
          
        if pending_computation_after is None:
          raise ValueError(f'pending_computation_after is None')

        if pending_computation_after.delay and pending_computation_after.delay > 2*sample_time:
          raise ValueError("Missing computation by multiple time steps is not supported, yet.")

        if pending_computation_after.delay < sample_time:
          # Evolve the state halfway and then update u.
          t_mid = pending_computation_after.t_end
          u_mid = pending_computation_after.u
          (t_mid, x_mid) = evolveState(t_start, x_start, u_after, t_mid)
          (t_end, x_end) = evolveState(t_mid,   x_mid,     u_mid, t_end)
        else: #u_delay and u_delay == sample_time:
          # Evolve state for entire time step and then update u_after
          (t_end, x_end) = evolveState(t_start, x_start, u_after, t_end)

        # elif u_delay and u_delay > sample_time:
        #   # Evolve the state for entire time step without updating u_after. 
        #   (t_end, x_end) = evolveState(t_start, x_start, u_after, t_end)
        
        # if u_delay is not None:
        #   u_pending_time = t_start + u_delay
          
        print(f'time_index={time_index}, t_start={t_start}, t_mid={t_mid}, t_end={t_end}, pending_computation_after={pending_computation_after}')
        print(f'u_before={u_before}, u_after={u_after}')

        # Save the data.
        time_step_series.append(t_end=t_end, 
                                x_end=x_end, 
                                u=u_after, 
                                pending_computation=pending_computation_after, 
                                t_mid=t_mid, 
                                x_mid=x_mid)

        if did_start_computation:
          n_new_u_values_computed += 1

        time_index += 1
        if time_index > 100:
          raise ValueError(f'time_index > 1000')
          

        # TODO: simulation_data_builder.end_of_simulation()
        # TODO: simulation_data_incremental = simulation_data_builder.to_dictionary()
        # TODO: writeJson(sim_dir + "simulation_data_incremental.json", simulation_data_incremental)
        print(f'time_step_series: {time_step_series}')
        writeJson(sim_dir + "simulation_data_incremental.json", time_step_series)
        print('\n=====\n')

        # Update values:
        u_before = u_after
        pending_computation_before = pending_computation_after
      # simulation_data_builder.update_u_at_sample_time(k=time_index, t=t, x=x, u_old=u, u_after=None)
    except (DataNotRecievedViaFileError, BrokenPipeError) as err:
      # TODO: simulation_data_builder.mark_end_of_simulation(repr(err))
      traceback.print_exc()

  return time_step_series

def convertStringToVector(vector_str: str):
  vector_str_list = vector_str.split(',') #.strip().split("\t")

  # Convert the list of strings to a list of floats.
  chars_to_strip = ' []\n'
  v = np.array([[np.float64(x.strip(chars_to_strip)),] for x in vector_str_list])
  
  if debug_interfile_communication_level >= 3:
    print('convertStringToVector():')
    printIndented('vector_str:', 1)
    printIndented(repr(vector_str), 1)
    printIndented('v:', 1)
    printIndented(repr(v), 1)

  return v


def checkAndStripInputLoopNumber(input_line):
  """ Check that an input line, formatted as "Loop <k>: <data>" 
  has the expected value of k (given by the argument "expected_k") """

  split_input_line = input_line.split(':')
  loop_input_str = split_input_line[0]

  # Check that the input line is in the expected format. 
  if not loop_input_str.startswith('Loop '):
    raise ValueError(f'The input_line "{input_line}" did not start with a loop label.')
  
  # Extract the loop number and convert it to an integer.
  input_loop_number = int(loop_input_str[len('Loop:'):])

  # if input_loop_number != expected_k:
  #   # If the first piece of the input line doesn't give the correct loop number.
  #   raise ValueError(f'The input_loop_number="{input_loop_number}" does not match expected_k={expected_k}.')
  #   
  # Return the part of the input line that doesn't contain the loop info.
  return split_input_line[1]

if __name__ == "__main__":
  raise ValueError("Not intended to be run directly")
