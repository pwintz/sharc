#!/usr/bin/env python3
""" 
This script computes the evolution of a system (plant) using control imputs received from a controller executable. 
The communication is done via pipe files contained in the simdir directory.
Instead of calling this script directly, call run_scarabintheloop.py
"""
import numpy as np
from scipy.integrate import ode
import scipy.signal
import numpy.linalg as linalg
import copy
# import argparse # Parsing of input args.

# Import contextmanager to allow defining commands to be used to create "with" blocks.
from contextlib import contextmanager 

import math
import time
import datetime
import traceback # Provides pretty printing of exceptions (https://stackoverflow.com/a/1483494/6651650)
from abc import abstractmethod, ABC

import scarabintheloop.scarabizor as scarabizor
from scarabintheloop.scarabizor import ScarabPARAMSReader
from scarabintheloop.utils import assertFileExists, printIndented, writeJson, readJson, printJson, assertLength, numpy_vec_to_list, list_to_numpy_vec, nump_vec_to_csv_string

import json
import csv
import re
import os

from typing import List, Set, Dict, Tuple, Union


class DataNotRecievedViaFileError(IOError):
  pass

debug_interfile_communication_level = 0
debug_dynamics_level = 0

class PipeReader:
  def __init__(self, filename: str):
    if debug_interfile_communication_level >= 1:
      print(f"About to open reader for {filename}. Waiting for it to available...")
    self.file = open(filename, 'r', buffering=1)

  def close(self):
    self.file.close()

  def read(self):
    input_line = self._waitForLineFromFile()
    input_line = checkAndStripInputLoopNumber(input_line)
    return input_line

  def _waitForLineFromFile(self):
    if debug_interfile_communication_level >= 1:
          print(f"Waiting for input_line from {self.file.name}.")
    input_line = self.file.readline()
    if debug_interfile_communication_level >= 1:
      print(f'Recieved input_line from {os.path.basename(self.file.name)}: {repr(input_line)}')
    return input_line

class PipeFloatReader(PipeReader):
  
  def __init__(self, filename: str):
    super().__init__(filename)

  def read(self):
    return float(super().read())

class PipeVectorReader(PipeReader):

  def __init__(self, filename: str):
    super().__init__(filename)

  def read(self):
    return convertStringToVector(super().read())

class DelayProvider(ABC):

  @abstractmethod
  def get_delay(self, metadata):
    """ 
    return t_delay, metadata 
    """
    # raise NotImplementedError(f'get_delay must be implemented by a subclass of DelayProvider.')
    return t_delay, instruction_count, cycles_count

class ScarabDelayProvider(DelayProvider):

  def __init__(self, sim_dir):
    self._stats_file_number = 0
    self.stats_reader = scarabizor.ScarabStatsReader(sim_dir)
    self.scarab_params_reader = ScarabPARAMSReader(sim_dir)

  def get_delay(self, metadata):
    if debug_interfile_communication_level >= 2:
      print('Waiting for statistics from Scarab.')

    self.stats_reader.waitForStatsFile(self._stats_file_number)
    t_delay = self.stats_reader.readTime(self._stats_file_number)
    instruction_count = self.stats_reader.readInstructionCount(self._stats_file_number)
    cycles_count = self.stats_reader.readCyclesCount(self._stats_file_number)
    self._stats_file_number += 1

    delay_metadata = {}
    params_out = self.scarab_params_reader.read_params_out()
    delay_metadata.update(params_out)
    delay_metadata["instruction_count"] = instruction_count
    delay_metadata["cycles_count"] = cycles_count
    return t_delay, delay_metadata

class OneTimeStepDelayProvider(DelayProvider):

  def __init__(self, sample_time):
    self.sample_time = sample_time
    
  def get_delay(self, metadata):
    t_delay = self.sample_time
    metadata = {}
    return t_delay, metadata

class NoneDelayProvider(DelayProvider):

  def __init__(self):
    pass

  def get_delay(self, metadata):
    t_delay = None
    metadata = {}
    return t_delay, metadata

class GaussianDelayProvider(DelayProvider):

  def __init__(self, mean, std_dev):
    self.mean = mean
    self.std_dev = std_dev

  def get_delay(self, metadata):
    # Generate a random number from the Gaussian distribution
    t_delay = np.random.normal(self.mean, self.std_dev)
    metadata = {}
    return t_delay, metadata

class LinearBasedOnIteraionsDelayProvider(DelayProvider):
  
  def __init__(self):
    pass

  def get_delay(self, metadata):
    # TODO: Move the computation delays generated by a model out of the plant_runner module.
    iterations = metadata["iterations"]
    delay_model_slope       = config_data["computation_delay_model"]["computation_delay_slope"]
    delay_model_y_intercept = config_data["computation_delay_model"]["computation_delay_y-intercept"]
    if delay_model_slope:
      if not delay_model_y_intercept:
        raise ValueError(f"delay_model_slope was set but delay_model_y_intercept was not.")
      t_delay = delay_model_slope * iterations + delay_model_y_intercept
      print(f"t_delay = {t_delay:.8g} = {delay_model_slope:.8g} * {iterations:.8g} + {delay_model_y_intercept:.8g}")
    else:
      print('Using constant delay times.')
      t_delay = config_data["computation_delay_model"]["fake_computation_delay_times"]
    return t_delay, metadata



class ControllerInterface(ABC):

  def __init__(self, computational_delay_provider: DelayProvider):
    self.computational_delay_provider = computational_delay_provider

  def open(self):
    """
    Open any resources that need to be closed.
    """
    pass

  def close(self):
    """
    Do cleanup of opened resources.
    """
    pass

  @abstractmethod
  def _write_x(self, x: np.ndarray):
    pass

  @abstractmethod
  def _write_t_delay(self, t: float):
    pass
    
  @abstractmethod
  def _read_u(self) -> np.ndarray:
    return u
    
  # TODO: Instead of having separate data streams for things like x_prediction and iterations, which 
  # TODO: will depend on the given system, write all of the system-specific data to a JSON file.
  # def _read_metadata(self, k) -> dict:
  #   pass

  @abstractmethod
  def _read_x_prediction(self) -> np.ndarray:
    return x_prediction
    
  @abstractmethod
  def _read_t_prediction(self) -> float:
    return t_prediction

  @abstractmethod
  def _read_iterations(self) -> int:
    return iterations
    
  def _read_metadata(self) -> int:
    x_prediction = self._read_x_prediction()
    t_prediction = self._read_t_prediction()
    iterations = self._read_iterations()
    if isinstance(x_prediction, np.ndarray):
      x_prediction = numpy_vec_to_list(x_prediction)
    metadata = {
      "x_prediction": x_prediction,
      "t_prediction": t_prediction,
      "iterations": iterations
    }

    return metadata
    
  def get_next_control_from_controller(self, x: np.ndarray):
    """
    Send the current state to the controller and wait for the responses. 
    Return values: u, x_prediction, t_prediction, iterations.
    """

    # The order of writing and reading to the pipe files must match the order in the controller.
    self._write_x(x)
    u = self._read_u()
    metadata = self._read_metadata() # TODO
    u_delay, delay_metadata = self.computational_delay_provider.get_delay(metadata)
    self._write_t_delay(u_delay)
    metadata.update(delay_metadata)

    if debug_interfile_communication_level >= 1:
      print('Input strings from C++:')
      printIndented(f"           u: {u}", 1)
      printIndented(f"metadata: {metadata}", 1)

    return u, u_delay, metadata
    
class PipesControllerInterface(ControllerInterface):

  def __init__(self, computational_delay_provider: DelayProvider, sim_dir):
    self.computational_delay_provider = computational_delay_provider
    self.sim_dir = sim_dir

  def open(self):
    """
    Open resources that need to be closed when finished.
    """
    self.x_infile = PipeVectorReader(self.sim_dir + '/x_c++_to_py') 
    self.u_infile = PipeVectorReader(self.sim_dir + '/u_c++_to_py') 
    self.x_predict_infile = PipeVectorReader(self.sim_dir + '/x_predict_c++_to_py') 
    self.t_predict_infile = PipeFloatReader(self.sim_dir + '/t_predict_c++_to_py') 
    self.iterations_infile = PipeFloatReader(self.sim_dir + '/iterations_c++_to_py') 
    self.x_outfile = file = open(self.sim_dir + 'x_py_to_c++', 'w', buffering=1)
    self.t_delay_outfile = file = open(self.sim_dir + 't_delay_py_to_c++', 'w', buffering=1)
    
    if debug_interfile_communication_level >= 1:
      print('Pipes are open') 

    return self  # Return the instance so that it's accessible as 'as' target

  def close(self):
    """ 
    Close all of the files we opened.
    """
    # Code to release the resource (e.g., close a file, database connection)
    self.x_infile.close()
    self.u_infile.close()
    self.x_predict_infile.close()
    self.t_predict_infile.close()
    self.iterations_infile.close()
    self.x_outfile.close()
    self.t_delay_outfile.close()

  def _write_x(self, x: np.ndarray):
    write_vec_to_file(self.x_outfile, x)

  def _write_t_delay(self, t_delay: float):
    t_delay_str = f"{t_delay:.8g}"
    self.t_delay_outfile.write(str(t_delay_str) + "\n")

  def _read_u(self):
    return self.u_infile.read()
    
  def _read_x_prediction(self):
    return self.x_predict_infile.read()
    
  def _read_t_prediction(self):
    return self.t_predict_infile.read()
    
  def _read_iterations(self):
    return self.iterations_infile.read()
    
    

def write_vec_to_file(file, x: np.ndarray):
  # Pass the string back to C++.
  x_out_string = nump_vec_to_csv_string(x)
  if debug_interfile_communication_level >= 1:
    print("x output line:" + repr(x_out_string))
  file.write(x_out_string + "\n")# Write to pipe to C++


class TimeStepSeries:
  def __init__(self, k0, t0, x0):
    if k0 is None:
      raise ValueError("k0 is None")
    if t0 is None:
      raise ValueError("t0 is None")
    if x0 is None:
      raise ValueError("x0 is None")
    
    self.k0 = k0
    self.t0 = t0
    self.x0 = self.cast_vector(x0)
    
    ### Time-index aligned values ###
    self.x = []
    self.u = []
    self.t = []
    self.k = [] 
    self.x_predictions = []
    self.t_predictions = [] # Absolute time

    ### Time-step aligned values (the intervals between indices) ###
    self.step_k = []
    self.step_t_start = []
    self.step_t_end = []
    self.step_u_pending = []
    self.step_u_delay = []
    self.metadata = [] # TODO: Should be step_metadata

  def __repr__(self):
      return (f"{self.__class__.__name__}("
              f"k0={self.k0},\n "
              f"t0={self.t0},\n "
              f"x0={self.x0},\n "
              f"x={self.x},\n "
              f"u={self.u},\n "
              f"t={self.t},\n "
              f"k={self.k},\n "
              f"x_predictions={self.x_predictions},\n "
              f"t_predictions={self.t_predictions},\n "
              f"step_k={self.step_k},\n "
              f"step_t_start={self.step_t_start},\n "
              f"step_t_end={self.step_t_end},\n "
              f"step_u_pending={self.step_u_pending},\n "
              f"step_u_delay={self.step_u_delay},\n "
              f"metadata={self.metadata})")

  def cast_vector(self, x):
    if x is None:
      return None
    if isinstance(x, float) or isinstance(x, int) or isinstance(x, list):
      return x
    elif isinstance(x, np.ndarray):
      return numpy_vec_to_list(x)
    raise ValueError(f'cast_vector(): Unexpected type: {type(x)}')
    

  def copy(self):
    copied = TimeStepSeries(self.k0, self.t0, self.x0)

    # Copy values.
    copied.x              = self.x.copy()
    copied.u              = self.u.copy()
    copied.t              = self.t.copy()
    copied.k              = self.k.copy()
    copied.x_predictions  = self.x_predictions.copy()
    copied.t_predictions  = self.t_predictions.copy()
    copied.step_k         = self.step_k.copy()
    copied.step_t_start   = self.step_t_start.copy()
    copied.step_t_end     = self.step_t_end.copy()
    copied.step_u_pending = self.step_u_pending.copy()
    copied.step_u_delay   = self.step_u_delay.copy()
    copied.metadata       = self.metadata.copy()
    return copied

  def append(self, t_end, x_end, u, u_pending, u_delay, t_mid=None, x_mid=None, metadata:dict=None):

    

    # is_x_end_None = x_end is None
    x_end     = self.cast_vector(x_end)
    u         = self.cast_vector(u)
    u_pending = self.cast_vector(u_pending)
    x_mid     = self.cast_vector(x_mid)

    if x_end is None:
      raise ValueError(f'x_end is None')

    if len(self.t) == 0:
      k       = self.k0
      t_start = self.t0
      x_start = self.x0
    else:
      k = self.k[-1] + 1
      t_start = self.t[-1]
      x_start = self.x[-1]

    if t_mid is None != x_mid is None:
      raise ValueError("t_mid is None != x_mid is None")
    # if t_mid is None != u_mid is None:
    #   raise ValueError("t_mid is None != u_mid is None")
    if t_start >= t_end:
      raise ValueError(f't_start={t_start} >= t_end={t_end}. self:{self}')
    if t_mid and (t_start > t_mid or t_mid > t_end):
      raise ValueError(f't_mid and (t_start > t_mid or t_mid > t_end)')

    if t_mid is None:
      self.t += [t_start, t_end]
      self.x += [x_start, x_end]
      self.u += [      u,     u]
      self.k += [      k,     k]

    else: # A mid point was given, indicating an update to u part of the way through.
      self.t += [t_start, t_mid,     t_mid,     t_end]
      self.x += [x_start, x_mid,     x_mid,     x_end]
      self.u += [       u,    u, u_pending, u_pending]
      self.k += [       k,    k,          k,        k]
      # The value of u_pending was applied, starting at t_mid, so it is no longer pending 
      # at the end of the sample. Thus, we set it to None.
      u_pending = None
      
      # if u_delay > t_mid - t_start:
      #   raise ValueError(f"u_delay={u_delay} > t_mid - t_start = {t_mid - t_start}")
      

    # TODO: Update predictions code.
    # self.x_predictions
    # self.t_predictions

    # The time-step aligned data all only has on
    self.step_k.append(k)
    self.step_t_start.append(t_start)
    self.step_t_end.append(t_end)
    self.step_u_pending.append(u_pending)
    self.step_u_delay.append(u_delay)
    self.metadata.append(metadata)

  def append_multiple(self, t_end, x_end, u, u_pending, u_delay, t_mid=None, x_mid=None, metadata=None):
    for i in range(len(t_end)):

      if t_mid is None:
        i_t_mid = None
      else:
        i_t_mid = t_mid[i]

      if x_mid is None:
        i_x_mid = None
      else:
        i_x_mid = x_mid[i]

      self.append(t_end[i], x_end[i], u[i], u_pending[i], u_delay[i], t_mid=i_t_mid, x_mid=i_x_mid, metadata=metadata)

  # Override the + operator
  def __add__(self, other):
    if not isinstance(other, TimeStepSeries):
      raise ValueError(f'Cannot concatenate this TimeStepSeries with a {type(other)} object.')
    
    # if self.is_empty():
    #   raise ValueError('Cannot concatenate onto an empty TimeStepSeries')
    if other.is_empty():
      return self

    if not self.is_empty():
      if self.k[-1] + 1 != other.k0:
        raise ValueError(f"Initial k does not match: self.k[-1] + 1 = {self.k[-1] + 1} != other.k0 = {other.k0}")
      if self.t[-1] != other.t0:
        raise ValueError("Initial time does not match: self.t[-1] != other.t0")
      if self.x[-1] != other.x0:
        raise ValueError("Initial state does not match: self.x[-1] != other.x0")

    concatenated = self.copy()
    concatenated.x              += other.x
    concatenated.u              += other.u
    concatenated.t              += other.t
    concatenated.k              += other.k
    concatenated.x_predictions  += other.x_predictions
    concatenated.t_predictions  += other.t_predictions
    concatenated.step_k         += other.step_k
    concatenated.step_t_start   += other.step_t_start
    concatenated.step_t_end     += other.step_t_end
    concatenated.step_u_pending += other.step_u_pending
    concatenated.step_u_delay   += other.step_u_delay
    concatenated.metadata       += other.metadata
    # concatenated.instruction_counts_list += other.instruction_counts_list
    # concatenated.cycles_counts_list += other.cycles_counts_list
    # concatenated.walltimes_list += other.walltimes_list

    return concatenated

  def truncate(self, n_timesteps=None, last_k=None):
    """
    Truncate this object to either have n_timesteps or to end at the index last_k.
    """

    if n_timesteps is None and last_k is None:
      raise ValueError("n_timesteps is None and last_k is None. Exactly one must be given!")
    
    if n_timesteps is None:
      n_timesteps = last_k - self.k0 + 1
    elif last_k is None:
      last_k = self.k0 + n_timesteps - 1
    else:
      raise ValueError("Either n_timesteps or last_k must be None.")

    if last_k < self.step_k[0]:
      raise ValueError("last_k was less than the first time step.")

    if self.n_time_steps() <= n_timesteps:
      return self.copy()
    
    truncated = self.copy()

    # Time-index aligned values
    last_index_of_last_k = max(ndx for ndx, k in enumerate(self.k) if k == last_k)
    ndxs = slice(0, last_index_of_last_k+1)
    truncated.x             = self.x[ndxs]
    truncated.u             = self.u[ndxs]
    truncated.t             = self.t[ndxs]
    truncated.k             = self.k[ndxs]
    truncated.x_predictions = self.x_predictions[ndxs]
    truncated.t_predictions = self.t_predictions[ndxs]

    # Time-step aligned values
    truncated.step_k         = self.step_k[:n_timesteps]
    truncated.step_t_start   = self.step_t_start[:n_timesteps]
    truncated.step_t_end     = self.step_t_end[:n_timesteps]
    truncated.step_u_pending = self.step_u_pending[:n_timesteps]
    truncated.step_u_delay   = self.step_u_delay[:n_timesteps]
    truncated.metadata       = self.metadata[:n_timesteps]
    # truncated.instruction_counts_list = self.instruction_counts_list[:n_timesteps]
    # truncated.cycles_counts_list      = self.cycles_counts_list[:n_timesteps]
    # truncated.walltimes_list          = self.walltimes_list[:n_timesteps]
    return truncated 

  def is_empty(self):
    return self.n_time_indices() == 0

  def n_time_indices(self):
    return len(self.t)

  def n_time_steps(self):
    return len(self.step_k)

  def find_first_late_timestep(self, sample_time):
    for (i_step, delay) in enumerate(self.step_u_delay):
      if delay is not None and delay > sample_time:
        has_missed_computation_time = True
        first_late_timestep = self.step_k[i_step]
        print(f'first_late_timestep: {first_late_timestep}')
        return first_late_timestep, has_missed_computation_time 
    
    has_missed_computation_time = False
    return None, has_missed_computation_time

  def printTimingData(self, label):
    timing_data = {
      "t0": self.t0,
      "k0": self.k0,
      "t": self.t,
      "k": self.k,
      "step_k": self.step_k,
      "step_t_start": self.step_t_start,
      "step_t_end": self.step_t_end,
    }
    printJson(label, timing_data)
    
    print(f'{label}')
    TimeStepSeries.print_sample_time_values("k", self.k)
    TimeStepSeries.print_time_step_values("time step", self.step_k)
    TimeStepSeries.print_sample_time_values("t(k)", self.t)
    TimeStepSeries.print_time_step_values("delay", self.step_u_delay)

  def print(self, label):
    print(f'{label}')
    TimeStepSeries.print_sample_time_values("k", self.k)
    TimeStepSeries.print_time_step_values("time step", self.step_k)
    TimeStepSeries.print_sample_time_values("t(k)", self.t)
    TimeStepSeries.print_sample_time_values("x1(k)", [x[0] for x in self.x])
    # TimeStepSeries.print_sample_time_values("x2(k)", [x[1] for x in self.x])
    # TimeStepSeries.print_sample_time_values("x3(k)", [x[2] for x in self.x])
    TimeStepSeries.print_sample_time_values("x4(k)", [x[3] for x in self.x])
    TimeStepSeries.print_sample_time_values("u([k, k+1))", [u[0] for u in self.u])
    TimeStepSeries.print_time_step_values("delay", self.step_u_delay)
    TimeStepSeries.print_time_step_values("u_pending", [u[0] for u in self.step_u_pending])

  @staticmethod
  def print_sample_time_values(label: str, values: list):
    values = [float('nan') if v is None else v for v in values]
    print(f"{label:>18}: " +  " --- ".join(f"{v:^7.3g}" for v in values))

  @staticmethod
  def print_time_step_values(label: str, values: list):
    try:
      str_list = []
      for v in values:
        if v is None:
          str_list += ["  None "] 
        elif isinstance(v, (float, int)) :
          str_list += [f"{v:^7.3g}"]
        else:
          raise TypeError(f'Unxpected type: {type(v)}')
          
      print(f"{label:>18}:    |  " + "  |           |  ".join(str_list) + "  |")
    except Exception as err:
      print(f'Failed to print values in {values}. Error: {err}')
      raise err


#   def to_dictionary(self) -> dict:
#     
#     if len(self.t) != len(self.x):
#       raise ValueError("len(t) != len(x)")
# 
#     # Create a JSON object for storing the data out, using all the values in config_data.
#     simulation_dictionary = {}
#     # simulation_dictionary["datetime_of_run"] = self.datetime_of_run
#     # simulation_dictionary["cause_of_termination"] = self.cause_of_termination
#     simulation_dictionary["x"] = self.x;
#     simulation_dictionary["u"] = self.u;
#     simulation_dictionary["t"] = self.t;
#     # simulation_dictionary["x_prediction"] = self.x_predictions;
#     # simulation_dictionary["t_prediction"] = self.t_predictions;
#     simulation_dictionary["time_indices"] = self.k;
#     simulation_dictionary["metadata"]     = self.metadata;
#     
#     simulation_dictionary["last_time_index"] = max(self.step_k) + 1
#         
#     # Read optimizer info.
#     # # TODO: Move the processing of the optimizer info out of "run_plant.py"
#     # with open(sim_dir + 'optimizer_info.csv', newline='') as csvfile:
#     #   csv_reader = csv.reader(csvfile, delimiter=',', quotechar='|')
#     #   
#     #   num_iterationss_list = []
#     #   costs_list = []
#     #   primal_residuals_list = []
#     #   dual_residuals_list = []
#     #   is_header = True
#     #   for row in csv_reader:
#     #     if is_header:
#     #       num_iterations_ndx = row.index('num_iterations')
#     #       cost_ndx = row.index('cost')
#     #       primal_residual_ndx = row.index('primal_residual')
#     #       dual_residual_ndx = row.index('dual_residual')
#     #       is_header = False
#     #     else:
#     #       num_iterationss_list.append(int(row[num_iterations_ndx]))
#     #       costs_list.append(float(row[cost_ndx]))
#     #       primal_residuals_list.append(float(row[primal_residual_ndx]))
#     #       dual_residuals_list.append(float(row[dual_residual_ndx]))
#     #     
#     # simulation_dictionary["num_iterations"]  = num_iterationss_list
#     # simulation_dictionary["cost"]            = costs_list
#     # simulation_dictionary["primal_residual"] = primal_residuals_list
#     # simulation_dictionary["dual_residual"]   = dual_residuals_list
# 
#     if not isinstance(simulation_dictionary, dict):
#       raise ValueError(f"Expected simulation_dictionary to be a dictionary, but instead it was a {type(simulation_dictionary)}.")
# 
#     return simulation_dictionary

class SimulationDataBuilder:
  def __init__(self):
    # scarab_params_reader may be None, in which case Scarab PARAMS are not read.
    # self.scarab_params_reader = scarab_params_reader
    self.time_step_series = None # initialized in start_of_simulation

    # # Data lists
    # self.xs_list = []
    # self.us_list = []
    # self.ts_list = []
    # self.x_predictions_list = []
    # self.t_predictions_list = [] # Absolute time
    # self.t_delays_list = [] # Relative time interval
    # self.time_indices_list = []
    # self.t_delays_list = []
    # self.instruction_counts_list = []
    # self.cycles_counts_list = []
    # self.walltimes_list = []

    # The cause_of_termination property records the simulation status and, ultimately, what caused the simulation to terminate. 
    # If there is an error during the simulation, cause_of_termination is set to its representation value.
    self.cause_of_termination = "Not started"

  # def snapshot_time_step(self, time_index: int, 
  #                       t: float, 
  #                       x: np.ndarray, 
  #                       u: np.ndarray, )

#   def snapshotState(self, k: int, t: float, xarray: np.ndarray, uarray: np.ndarray, description: str):
#     """ Define a function for printing the current state of the system to 
#     the console and saving the state to the data files. """
#     if uarray is None:
#       raise ValueError("uarray was None.")
#     # x_str = nump_vec_to_csv_string(xarray)
#     # u_str = nump_vec_to_csv_string(uarray)
# 
#     if debug_interfile_communication_level >= 1:
#       print(f'Snapshotting State k={k}, t={t} s, ({description}):')
#       printIndented(f'x: {xarray}', 1)
#       printIndented(f'u: {uarray}', 1)
# 
#     # Add xarray and uarray to the cumulative lists. 
#     # We want xarray to be stored as a single list of numbers, but the 
#     # tolist() function creates a nested lists, with the outer list containing
#     # a single list. Thus, we use "[0]" to reference the inner list. 
# 
#       
#     self.time_indices_list.append(k)
#     self.xs_list.append(numpy_vec_to_list(xarray))
#     self.us_list.append(numpy_vec_to_list(uarray))
#     self.ts_list.append(t)
#     
#     if len(self.time_indices_list) != len(self.xs_list):
#       raise ValueError("len(time_indices_list) != len(xs_list)")
# 
#   def snapshotDelay(self, k: int, t_delay: float, instruction_count: int, cycles_count: int, description: str=""):
#     """ Define a function for recording delays. """
# 
#     if debug_interfile_communication_level >= 1:
#       print(f'Snapshotting Delays k={k}, ({description}):')
#       printIndented(f't_delay: {t_delay}', 1)
#       printIndented(f'instruction_count: {instruction_count}', 1)
#       printIndented(f'cycles_count: {cycles_count}', 1)
# 
#     self.t_delays_list.append(t_delay)
#     self.instruction_counts_list.append(instruction_count)
#     self.cycles_counts_list.append(cycles_count)
# 
#     # if len(self.time_indices_list) != len(self.xs_list):
#       # raise ValueError("len(time_indices_list) != len(xs_list)")
# 
#   def snapshotPrediction(self, t_prediction: float, x_prediction_array: np.ndarray, description: str):
#     """ Define a function for printing the prediction to 
#     the console and saving the state to the data files. """
#     x_predict_str = nump_vec_to_csv_string(x_prediction_array)
#     t_predict_str = f"{t_prediction:.8}"
# 
#     if debug_interfile_communication_level >= 1:
#       print(f'Snapshotting Prediction ({description})')
#       printIndented(f'x prediction: {x_predict_str}', 1)
#       printIndented(f't prediction: {t_predict_str}', 1)
# 
#     # Add xarray and uarray to the cumulative lists. 
#     # We want xarray to be stored as a single list of numbers, but the 
#     # tolist() function creates a nested lists, with the outter list containing
#     # a single list. Thus, we use "[0]" to reference the inner list. 
#     self.x_predictions_list.append(x_prediction_array.transpose().tolist()[0])
#     self.t_predictions_list.append(t_prediction)

  def start_of_simulation(self, k0, t0, x0):
    self.walltime_start_of_loop = time.time()
    self.cause_of_termination = "In Progress"
    self.datetime_of_run = datetime.datetime.now().isoformat()
    self.time_step_series = TimeStepSeries(k0=k0, t0=t0, x0=x0)
  
  def end_of_simulation(self, cause_of_termination=None):
    self.walltimes_list.append(time.time() - self.walltime_start_of_loop)
    if not cause_of_termination:
      self.cause_of_termination = "Finished"
    else:
      self.cause_of_termination = cause_of_termination

#   def update_u(self, 
#                 k_old: int, # Time index.
#                 k_new: int, # Time index.
#                 t: float, 
#                 x: np.ndarray, 
#                 u_old: np.ndarray, 
#                 u_new: np.ndarray, 
#                 description: str = ""):
#     # Check arguments
#     if k_old == None != u_old == None:
#       raise ValueError("update_u(): k_old == None != u_old == None. They should both be None or neither be None!")
#     
#     if k_new == None != u_new == None:
#       raise ValueError("update_u(): k_new == None != u_new == None. They should both be None or neither be None!")
#     
#     def assert_is_np_array(array):
#       if not isinstance(array, np.ndarray) and array is not None:
#         raise ValueError(f'Expected {array} to be an np.array but instead it is a {type(array)}')
#     
#     # Check that x, u_new, and u_old are numpy arrays (or empty)
#     assert_is_np_array(x)
#     assert_is_np_array(u_new)
#     assert_is_np_array(u_old)
#     
#     if u_old == None: # No old -> Setting the initial u value.
#       self.snapshotState(k_new, t, x, u_new, f'(time index={k_new} {description} - initial')
#     else: # Old and new -> Don't compute the next control value.
#       self.snapshotState(k_old, t, x, u_old, f'(time index={k_old} {description} - before')
#       if u_new:
#         self.snapshotState(k_new, t, x, u_new, f'(time index={k_new} {description} - after')
# 
#     return u_new, k_new
# 
#   def set_initial_u(self, 
#                     k: int, # Time index.
#                     t: float, 
#                     x: np.ndarray, 
#                     u: np.ndarray):
#     print(f'k={k}, t={t}, x={x}, u={u}, Initial value')
#     return self.update_u(k_old=None, k_new = k, t=t, x=x, u_old=None, u_new=u, description="Initial value")
# 
#   def update_u_at_sample_time(self, 
#                               k: int, # Time index.
#                               t: float, 
#                               x: np.ndarray, 
#                               u_old: np.ndarray, 
#                               u_new: np.ndarray, 
#                               description: str = None):
#     print(f'k={k}, t={t}, x={x}, u_old={u_old}, u_new={u_new}, description={description}')
#     # If no "old" given, then keep the current time step.
#     if u_old is None: 
#       raise ValueError('u_old is None')
#     
#     if u_new is None:
#       k_new = None
#     else:
#       k_new = k+1
# 
#     return self.update_u(k_old=k, k_new = k_new, t=t, x=x, u_old=u_old, u_new=u_new, description=description)
# 
#   def update_u_between_sample_times(self, 
#                                     k: int, # Time index.
#                                     t: float, 
#                                     x: np.ndarray, 
#                                     u_old: np.ndarray, 
#                                     u_new: np.ndarray, 
#                                     description: str = None):
#     raise ValueError("I don't expect this case right now.")
#     # We keep the same 'k' because we have not reached the new sample time.
#     return self.update_u(k_old=k, k_new = k, t=t, x=x, u_old=u_old, u_new=u_new, description=description)
#   
#   def build(self):
# 
#     time_series = TimeSeries(
#       xs_list = self.xs_list,
#       us_list = self.us_list,
#       ts_list = self.ts_list,
#       time_indices_list = self.time_indices_list,
#       t_delays_list = self.t_delays_list,
#       instruction_counts_list = self.instruction_counts_list,
#       cycles_counts_list = self.cycles_counts_list,
#       walltimes_list = self.walltimes_list,
#       x_predictions_list = self.x_predictions_list,
#       t_predictions_list = self.t_predictions_list
#     )

class ComputationData:

  def __init__(self, t_start, delay, u):
    self.t_start = t_start
    self.delay = delay
    self.t_end = t_start + delay
    self.u

def get_u(t, x, u_current, u_pending, u_pending_time, controller_interface):
  """ 
  Get an (possibly) updated value of u. 
  Returns: u_current, u_delay, u_pending, u_pending_time, metadata,
  where u_current is the value of u that should start being applied immediately (at t). 
  
  If the updated value requires calling the controller, then u_delay  

  This function is tested in <root>/tests/test_scarabintheloop_plant_runner.py/Test_get_u
  """

  if u_pending is None != u_pending_time is None:
    raise ValueError(f'u_pending={u_pending} is None != u_pending_time={u_pending_time} is None')
  
  # If no u_pending...
  if u_pending is None:
    # There is no u_pending, then we run the computation of the next control value. The current u does not update, because it takes time for the control to be computed.
    u = u_current
    u_pending, u_delay, metadata = controller_interface.get_next_control_from_controller(x)
    u_pending_time = t + u_delay
    return u, u_delay, u_pending, u_pending_time, metadata
  else: # Otherwise, no computation: u_pending and u_pending_time are given...
    # no computation, so no delay or metadata.
    u_delay = None
    metadata = None

    # Sanity check.
    if u_pending_time is None:
      raise ValueError(f"u_pending_time is None. u_pending: {u_pending}")
  
    # If before the time when u_pending is 'ready', then keep u_current and u_pending unchanged.
    if t < u_pending_time:
      u = u_current
      return u, u_delay, u_pending, u_pending_time, metadata
    
    if t >= u_pending_time:
      u = u_pending
      u_pending = None
      u_pending_time = None
      return u, u_delay, u_pending, u_pending_time, metadata

    raise ValueError('Unexpected case.') 



# 
# class PlantRunner:
# 
#   def __init__(self, computational_delay_provider, 
# only_update_control_at_sample_times
# is_parallelized):
# 
#               #  evolveState,
#               #  simulation_data_builder, 
#               #  controller_interface, 
#               #  computational_delay_provider,
#               #  n_controller_computations,
#               #  first_time_step,
#               #  sample_time):
#     self.evolveState = evolveState
#     self.simulation_data_builder = simulation_data_builder
#     self.controller_interface = controller_interface
#     self.computational_delay_provider = computational_delay_provider
#     self.n_controller_computations = n_controller_computations
#     self.first_time_step = first_time_step
#     self.sample_time = sample_time
# 
#   def run(first_time_step, sample_time, x0)

# def run_with_configured_objs(evolveState,
#                              simulation_data_builder, 
#                              controller_interface, 
#                              computational_delay_provider,
#                              n_controller_computations,
#                              first_time_step,
#                              sample_time,
#                              x0,
#                              u0,
#                              t0
#                              ):
#     pass
  

def computation_delay_provider_factory(computation_delay_name: str, sim_dir, sample_time):
  if isinstance(computation_delay_name, str):
    computation_delay_name = computation_delay_name.lower()
  if computation_delay_name == "none":
    return NoneDelayProvider()
  elif computation_delay_name == "gaussian":
    computational_delay_provider = GaussianDelayProvider(mean=0.24, std_dev=0.05)
  elif computation_delay_name == "scarab":
    return ScarabDelayProvider(sim_dir)
  elif computation_delay_name == "onestep":
    return OneTimeStepDelayProvider(sample_time)
  elif isinstance(computation_delay_name, DelayProvider):
    return computation_delay_name
  else:
    raise ValueError(f'Unexpected computation_delay_name: {computation_delay_name}')
    
@contextmanager
def controller_interface_factory(controller_interface_selection, computation_delay_provider, sim_dir):
  """ 
  Generate the desired ControllerInterface object based on the value of "controller_interface_selection". Typically the value will be the string "pipes", but a ControllerInterface interface object can also be passed in directly to allow for testing.
  
  Example usage:

    with controller_interface_factory("pipes", computation_delay_provider, sim_dir) as controller_interface: 
        <do stuff with controller_interface>
    
  When the "with" block is left, controller_interface.close() is called to clean up resources.
  """

  if isinstance(controller_interface_selection, str):
    controller_interface_selection = controller_interface_selection.lower()

  if controller_interface_selection == "pipes":
    controller_interface = PipesControllerInterface(computation_delay_provider, sim_dir)
  elif isinstance(controller_interface_selection, ControllerInterface):
    controller_interface = controller_interface_selection
  else:
    raise ValueError(f'Unexpected controller_interface: {controller_interface}')

  try:
    controller_interface.open()
    yield controller_interface.open()
  finally:
    controller_interface.close()


def run(sim_dir: str, config_data: dict, evolveState) -> dict:
  if not sim_dir.endswith("/"):
    sim_dir += "/"
  print(f"Start of plant_runner.run()  in {sim_dir}")

  # Settings
  only_update_control_at_sample_times = config_data["only_update_control_at_sample_times"]
  use_scarab_delays = not config_data["Simulation Options"]["use_fake_scarab_computation_times"]
  is_parallelized = config_data["Simulation Options"]["parallel_scarab_simulation"]

  # Update some setting to make sure 
  if is_parallelized:
    use_scarab_delays = False
    only_update_control_at_sample_times = True

  max_time_steps = config_data["max_time_steps"]
  sample_time = config_data["system_parameters"]["sample_time"] # Discrete sample period.
  first_time_index = config_data['first_time_index']

  computation_delay_provider = computation_delay_provider_factory(config_data["Simulation Options"]["computation_delay_provider"], sim_dir, sample_time)

  # Get the dynamics definition.
  n = config_data["system_parameters"]["state_dimension"]
  m = config_data["system_parameters"]["input_dimension"]

  # Read the initial control value.
  x0 = list_to_numpy_vec(config_data['x0'])
  u0 = list_to_numpy_vec(config_data['u0'])
  u_prev = u0

  simulation_data_builder = SimulationDataBuilder()
  
  if config_data["u_pending"]:
    u_pending            = list_to_numpy_vec(config_data["u_pending"])
    # u_pending_time_index = config_data["u_pending_time_index"]
    u_pending_time       = config_data["u_pending_time"]
  else:
    u_pending            = None
    # u_pending_time_index = None
    u_pending_time       = None

  with controller_interface_factory("pipes", computation_delay_provider, sim_dir) as controller_interface:

    # computational_delay_provider = ScarabDelayProvider(sim_dir)
    computational_delay_provider = OneTimeStepDelayProvider(sample_time)
    # computational_delay_provider = GaussianDelayProvider(mean=0.24, std_dev=0.05)

    try:
      x = x0
      u_current = u0
      time_index = first_time_index
      t = time_index * sample_time
      # TODO: simulation_data_builder.start_of_simulation(k0=first_time_index, t0=t, x0=x0)
      # u, time_index = simulation_data_builder.set_initial_u(time_index, t, x, u0)

      # The number of time steps that the controller has been computed. 
      # When there is a pending 'u' value, there may be several time steps that don't compute new control values.
      n_new_u_values_computed = 0

      time_step_series = TimeStepSeries(k0=first_time_index, t0=t, x0=x0)
      while n_new_u_values_computed < max_time_steps:
        u_current, u_delay, u_pending, u_pending_time, metadata = get_u(t, x, u_current, u_pending, u_pending_time, controller_interface)

        t_start = time_index * sample_time
        t_mid = None
        t_end = (time_index + 1) * sample_time
        x_start = x
        x_mid = None
        
        u_mid   = None
        u_end   = None

        if u_delay and u_delay > 2*sample_time:
          raise ValueError("Missing computation by multiple time steps is not supported, yet.")

        if u_pending is None:
          # Evolve state for entire time step without updating u.
          (t_end, x_end) = evolveState(t_start, x_start, u_current, t_end)
        elif u_delay and u_delay < sample_time:
          # Evolve the state halfway and then update u.
          t_mid = t + u_delay
          (t_mid, x_mid) = evolveState(t_start, x_start, u_current, t_mid)
          (t_end, x_end) = evolveState(t_mid,   x_mid,   u_pending, t_end)
        else: #u_delay and u_delay == sample_time:
          # Evolve state for entire time step and then update u
          (t_end, x_end) = evolveState(t_start, x_start, u_current, t_end)

        # elif u_delay and u_delay > sample_time:
        #   # Evolve the state for entire time step without updating u. 
        #   (t_end, x_end) = evolveState(t_start, x_start, u_current, t_end)
        
        # if u_delay is not None:
        #   u_pending_time = t_start + u_delay
          
        print(f'time_index={time_index}, t_start={t_start}, t_mid={t_mid}, t_end={t_end}, u_delay={u_delay}')

        # Save the data.
        time_step_series.append(t_end=t_end, 
                                x_end=x_end, 
                                u=u_current, 
                                u_pending=u_pending, 
                                u_delay=u_delay, 
                                t_mid=t_mid, 
                                x_mid=x_mid, 
                                metadata=metadata)

        if u_pending_time and u_pending_time <= t_end:
          u = u_pending
          u_pending = None

        if u_delay is not None:
          n_new_u_values_computed += 1

        time_index += 1

#         if u_pending:
#           if first_time_index >= u_pending_time_index:
#             raise ValueError(f"When u_pending is given, u_pending_time_index must be larger than the first time index, but instead u_pending_time_index = {u_pending_time_index} and first_time_index = {first_time_index}.")
#           while time_index < u_pending_time_index - 1:
#             u, time_index = simulation_data_builder.update_u_at_sample_time(time_index, t, x, u_old=u, u_new=u, 
#                               description=f"Keeping initial u while waiting to apply u_pending at k={u_pending_time_index}.")
#             
#             t_start = time_index * sample_time
#             t_end = (time_index + 1) * sample_time
#             (t, x) = evolveState(t_start, x, u, t_end)
#             simulation_data_builder.snapshotDelay(time_index, math.nan, math.nan, math.nan)
# 
#           u, time_index = simulation_data_builder.update_u_at_sample_time(time_index, t, x, u_old=u, u_new=u_pending)
#           t_start = time_index * sample_time
#           # Set t_end to the time when the computation finishes.
#           t_end = (time_index + 1) * sample_time
#           (t, x) = evolveState(t_start, x, u, t_end)
# 
#         for time_step in range(0, max_time_steps):
#           print(f'Start of time step {time_index}.')
#           
#           u, x_prediction, t_prediction, iterations = controller_interface.get_next_control_from_controller(time_index, x)
#           t_delay, instruction_count, cycles_count = computational_delay_provider.get_delay(time_index, iterations)
#           controller_interface._write_t_delay(t_delay)
# 
#           simulation_data_builder.snapshotDelay(time_index, t_delay, instruction_count, cycles_count)
#           simulation_data_builder.snapshotDelay(time_index, math.nan, math.nan, math.nan)
#           
#           print(f"Delay time: {t_delay:.8g} seconds ({100*t_delay/sample_time:.3g}% of sample time).")
#           simulation_data_builder.snapshotPrediction(t_prediction, x_prediction, "Prediction")
# 
#           n_samples_without_finishing_computation = math.floor(t_delay/sample_time)
#           n_samples_until_next_sample_after_computation_finishes = n_samples_without_finishing_computation + 1
# 
#           if debug_dynamics_level >= 1:
#             print(f"t_delay={t_delay}, sample_time={sample_time:.2f}.")
# 
#           if only_update_control_at_sample_times:
#             t_start = t
#             # Set t_end to the time when the computation finishes.
#             t_end = t + (n_samples_without_finishing_computation+1)*sample_time
#             (t, x) = evolveState(t_start, x, u_prev, t_end)
#             u, time_index = simulation_data_builder.update_u_at_sample_time(k=time_index, t=t, x=x, u_old=u_prev, u_new=u)
#             # simulation_data_builder.snapshotState(-1, t, x, u, f"After full sample interval with {n_samples_without_finishing_computation} missed computation updates.")
#             u_prev = u
#         else: # Update when the computation finishes, without waiting for the next sample time.
#           t_start = t
#           t_computation_update = t + t_delay
#           t_end = t + (n_samples_without_finishing_computation + 1)*sample_time
# 
#           # Evolve x over the one or more sample periods where the control is not updated.
#           (t_mid, x_mid) = evolveState(t_start, x, u_prev, t_computation_update)
# 
#           # Snapshot at the computation time with the old control value.
#           snapshotState(time_index, t, x, u_prev, f"After delay - Previous control. Missed {n_samples_without_finishing_computation} samples without updating controller.")
#           
#           # Snapshot at the computation time with the new control value.
#           snapshotState(time_index, t, x, u, f"After delay - New control. Missed {n_samples_without_finishing_computation} samples without updating controller.")
# 
#           (t, x) = evolveState(t_computation_update, x, u, t_end)
# 
#           # Save the state at the end of the sample period.
#           snapshotState(time_index, t, x, u, f"End of sample period. Missed {n_samples_without_finishing_computation} samples without updating controller.")
#         
#           u_prev = u

        # TODO: simulation_data_builder.end_of_simulation()
        # TODO: simulation_data_incremental = simulation_data_builder.to_dictionary()
        # TODO: writeJson(sim_dir + "simulation_data_incremental.json", simulation_data_incremental)
        print(f'time_step_series: {time_step_series}')
        writeJson(sim_dir + "simulation_data_incremental.json", time_step_series)
        print('\n=====\n')
      # simulation_data_builder.update_u_at_sample_time(k=time_index, t=t, x=x, u_old=u, u_new=None)
    except (DataNotRecievedViaFileError, BrokenPipeError) as err:
      # TODO: simulation_data_builder.mark_end_of_simulation(repr(err))
      traceback.print_exc()

  return time_step_series

def convertStringToVector(vector_str: str):
  vector_str_list = vector_str.split(',') #.strip().split("\t")

  # Convert the list of strings to a list of floats.
  chars_to_strip = ' []\n'
  v = np.array([[np.float64(x.strip(chars_to_strip)),] for x in vector_str_list])
  
  if debug_interfile_communication_level >= 3:
    print('convertStringToVector():')
    printIndented('vector_str:', 1)
    printIndented(repr(vector_str), 1)
    printIndented('v:', 1)
    printIndented(repr(v), 1)

  return v




def checkAndStripInputLoopNumber(input_line):
  """ Check that an input line, formatted as "Loop <k>: <data>" 
  has the expected value of k (given by the argument "expected_k") """

  split_input_line = input_line.split(':')
  loop_input_str = split_input_line[0]

  # Check that the input line is in the expected format. 
  if not loop_input_str.startswith('Loop '):
    raise ValueError(f'The input_line "{input_line}" did not start with a loop label.')
  
  # Extract the loop number and convert it to an integer.
  input_loop_number = int(loop_input_str[len('Loop:'):])

  # if input_loop_number != expected_k:
  #   # If the first piece of the input line doesn't give the correct loop number.
  #   raise ValueError(f'The input_loop_number="{input_loop_number}" does not match expected_k={expected_k}.')
  #   
  # Return the part of the input line that doesn't contain the loop info.
  return split_input_line[1]

if __name__ == "__main__":
  raise ValueError("Not intended to be run directly")
